{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup, Imports, and Data Loading (Based on original Cell 98)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load Data (Based on original Cell 99)\n",
    "# Assuming your file is named 'housing.csv'\n",
    "df = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Handle Missing Values (Based on original Cell 101)\n",
    "# Drop rows with NA values (specifically in 'total_bedrooms')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define X and y (Based on original Cell 102)\n",
    "# Define Features (X) and Target (y) before transformations\n",
    "X = df.drop('median_house_value', axis=1)\n",
    "y = df['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Train-Test Split (The Consistency Fix)\n",
    "# FIX: Use a fixed random_state=42 for reproducible results. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Feature Transformation Function (The Data Leakage Fix)\n",
    "def transform_features(X_data):\n",
    "    \"\"\"Applies Log Transform, Feature Engineering, and OHE. Operates on a copy of data.\"\"\"\n",
    "\n",
    "    # Work on a copy to avoid SettingWithCopyWarning\n",
    "    X_transformed = X_data.copy()\n",
    "\n",
    "    # 1. Log Transform for Skewed Features (as in video [00:13:24])\n",
    "    skewed_features = ['total_rooms', 'total_bedrooms', 'population', 'households']\n",
    "    for col in skewed_features:\n",
    "        # np.log1p is log(x + 1)\n",
    "        X_transformed[col] = np.log1p(X_transformed[col])\n",
    "\n",
    "    # 2. Feature Engineering (as in video [00:20:00])\n",
    "    X_transformed['bedroom_ratio'] = X_transformed['total_bedrooms'] / X_transformed['total_rooms']\n",
    "    X_transformed['household_rooms'] = X_transformed['total_rooms'] / X_transformed['households']\n",
    "\n",
    "    # 3. One-Hot Encode (OHE) 'ocean_proximity' (as in video [00:16:28])\n",
    "    # drop_first=True avoids multicollinearity\n",
    "    ohe_columns = pd.get_dummies(X_transformed['ocean_proximity'], prefix='ocean', drop_first=True)\n",
    "    X_transformed = X_transformed.join(ohe_columns)\n",
    "    X_transformed.drop('ocean_proximity', axis=1, inplace=True)\n",
    "    \n",
    "    return X_transformed\n",
    "\n",
    "# Apply the transformations to the Training and Test sets separately\n",
    "X_train_processed = transform_features(X_train)\n",
    "X_test_processed = transform_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Column Alignment for Robustness\n",
    "# Safety step: Ensure test set columns match training set columns after OHE\n",
    "missing_cols = set(X_train_processed.columns) - set(X_test_processed.columns)\n",
    "for c in missing_cols:\n",
    "    X_test_processed[c] = 0\n",
    "\n",
    "# Re-order test columns to match training columns\n",
    "X_test_processed = X_test_processed[X_train_processed.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Scaling Numerical Features (Based on original Cell 110)\n",
    "# FIX: Scaling is fit *only* on the training data to prevent leakage.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and Transform Training Data\n",
    "X_train_scaled = scaler.fit_transform(X_train_processed)\n",
    "\n",
    "# Transform Test Data using the fitted scaler\n",
    "X_test_scaled = scaler.transform(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Train Linear Regression (Based on original Cell 113)\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Score Linear Regression (Based on original Cell 114)\n",
    "# Expected Score (R^2): ~0.66\n",
    "print(f\"Linear Regression R^2 Score: {reg.score(X_test_scaled, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Train Random Forest Regressor (Based on original Cell 115)\n",
    "# FIX: Set random_state for reproducible Random Forest results.\n",
    "forest = RandomForestRegressor(random_state=42) \n",
    "forest.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Score Random Forest Regressor (Based on original Cell 116)\n",
    "# Expected Score (R^2): ~0.80\n",
    "print(f\"Random Forest R^2 Score (Default): {forest.score(X_test_scaled, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Grid Search Setup and Fit (Based on original Cell 126)\n",
    "# Use a fixed random_state for the base estimator\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Adjusted param_grid based on common practice and video findings (more estimators/depths)\n",
    "param_grid = {\n",
    "    \"n_estimators\" : [100, 200, 300], \n",
    "    \"max_features\" : [2, 4, 6, 8],\n",
    "    \"max_depth\": [None, 5, 8],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(reg, param_grid, n_jobs=-1, cv=5, scoring=\"neg_mean_squared_error\", return_train_score=True)\n",
    "\n",
    "# Fit on the correctly scaled and processed training data\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Get Best Estimator (Based on original Cell 128)\n",
    "best_reg = grid_search.best_estimator_\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Score Best Estimator (Based on original Cell 129)\n",
    "# Score the best model found by the Grid Search\n",
    "print(f\"Random Forest R^2 Score (Grid Search): {best_reg.score(X_test_scaled, y_test):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}